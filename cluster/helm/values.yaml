model:
  name: model
  image: rlcr.io/ramalama/gemma-3-4b-it:llamacpp-cuda
  replicaCount: 1
  port: 8080
  gpuCount: 1
  resources: {}

llamaStack:
  image: docker.io/llamastack/distribution-starter:latest
  replicaCount: 1
  port: 8000
  resources: {}

ragDatabase:
  name: qdrant
  image: 620339869704.dkr.ecr.us-east-1.amazonaws.com/gcp_ecr_repository:latest
  replicaCount: 1
  port: 6333
  storage: 10Gi
  collectionName: rag
  resources: {}

openWebUi:
  openAiApiBaseUrl: http://llama-stack.default.svc.cluster.local:8000
  containerPort: 8080
