model:
  image: rlcr.io/ramalama/gemma-3-4b-it:llamacpp-cuda
  replicaCount: 1
  port: 8080
  gpuCount: 1 

llamaStack:
  image: llama-stack/distribution-meta-reference-gpu:latest
  replicaCount: 1
  port: 8000

  config:
    modelEndpoint: "http://model:8080"
    vectorHost: "rag-database"
    vectorPort: 6333

  resources: {}

rag-database:
  image: 
  replicaCount: 1
  port: 6333
  storage: 10Gi
  resources: {}

